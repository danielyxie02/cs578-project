{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Grant Parker\n",
    "#Functions/packages/code taken, adapated, and modified from https://github.com/microsoft/nni/blob/36ba04c94e51eaa2a88b9e6e0a4077f3a9f93004/examples/compression/pruning/scheduled_pruning.py\n",
    "\n",
    "#NNI packages\n",
    "import nni\n",
    "from nni.compression import TorchEvaluator\n",
    "from nni.compression.pruning import TaylorPruner, AGPPruner\n",
    "from nni.compression.utils import auto_set_denpendency_group_ids\n",
    "from nni.compression.speedup import ModelSpeedup\n",
    "\n",
    "\n",
    "#pytorch packages \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#tensor packages \n",
    "from tensorboardX import SummaryWriter\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "from models import LeNet_5\n",
    "from datasets import get_mnist_dataloaders\n",
    "\n",
    "import models\n",
    "import datasets\n",
    "#import modelsNNI\n",
    "\n",
    "import time\n",
    "\n",
    "#imports from Models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import inspect\n",
    "\n",
    "#importing Resnet \n",
    "import torchvision.models as modelsRes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def train(model: torch.nn.Module, optimizer: torch.optim.Optimizer, training_step,\n",
    "          lr_scheduler: _LRScheduler, max_steps: int, max_epochs: int):\n",
    "    assert max_epochs is not None or max_steps is not None\n",
    "    #train_loader, test_loader = prepare_dataloader()\n",
    "    #grant addittion ---\n",
    "    batch_size = 100\n",
    "    train_loader, test_loader = datasets.get_mnist_dataloaders(batch_size,batch_size)\n",
    "\n",
    "    #----\n",
    "    max_steps = max_steps if max_steps else max_epochs * len(train_loader)\n",
    "    max_epochs = max_steps // len(train_loader) + (0 if max_steps % len(train_loader) == 0 else 1)\n",
    "    count_steps = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = training_step((data, target), model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count_steps += 1\n",
    "            if count_steps >= max_steps:\n",
    "                acc = evaluate(model, test_loader)\n",
    "                print(f'[Training Epoch {epoch} / Step {count_steps}] Final Acc: {acc}%')\n",
    "                return\n",
    "        acc = evaluate(model, test_loader)\n",
    "        print(f'[Training Epoch {epoch} / Step {count_steps}] Final Acc: {acc}%')\n",
    "\n",
    "def evaluate(model: torch.nn.Module, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return 100 * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def training_step(batch, model: torch.nn.Module):\n",
    "    output = model(batch[0])\n",
    "    loss = F.cross_entropy(output, batch[1])\n",
    "    return loss\n",
    "\n",
    "def prepare_optimizer(model: torch.nn.Module):\n",
    "    optimize_params = [param for param in model.parameters() if param.requires_grad == True]\n",
    "    optimizer = nni.trace(Adam)(optimize_params, lr=0.01)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[Training Epoch 0 / Step 600] Final Acc: 98.08%\n",
      "[Training Epoch 1 / Step 1200] Final Acc: 98.53%\n",
      "[Training Epoch 2 / Step 1800] Final Acc: 98.38%\n",
      "[Training Epoch 3 / Step 2400] Final Acc: 98.56%\n",
      "[Training Epoch 4 / Step 3000] Final Acc: 98.49%\n",
      "[Training Epoch 5 / Step 3600] Final Acc: 98.36%\n",
      "[Training Epoch 6 / Step 4200] Final Acc: 98.41%\n",
      "[Training Epoch 7 / Step 4800] Final Acc: 98.44%\n",
      "[Training Epoch 8 / Step 5400] Final Acc: 98.25%\n",
      "[Training Epoch 9 / Step 6000] Final Acc: 98.33%\n",
      "Original model paramater number:  61706\n",
      "Original model after 10 epochs finetuning acc:  98.33 %\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"start\")\n",
    "    #grants additions \n",
    "\n",
    "    model = models.LeNet_5().to(device)\n",
    "    #model = modelsRes.resnet18().to(device)\n",
    "    #optimizer = optim.NAdam(model.parameters()) -- did not use this \n",
    "    optimizer = prepare_optimizer(model)\n",
    "    batch_size = 100\n",
    "    train(model, optimizer, training_step, lr_scheduler=None, max_steps=None, max_epochs=50)\n",
    "\n",
    "    train_loader, test_loader = datasets.get_mnist_dataloaders(batch_size, batch_size)\n",
    "    print('Original model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "    print('Original model after 10 epochs finetuning acc: ', evaluate(model, test_loader), '%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Epoch 0 / Step 600] Final Acc: 48.34%\n",
      "[Training Epoch 1 / Step 1000] Final Acc: 70.8%\n",
      "[2023-12-06 20:01:13] \u001b[32mStart to speedup the model...\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mdim0 sparsity: 0.909091\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "0 Filter\n",
      "[2023-12-06 20:01:13] \u001b[32mdim0 sparsity: 0.909091\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mInfer module masks...\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate original variables\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_module: conv1, weight:  0.8333 bias:  0.8333 , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_function: relu, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_function: max_pool2d, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_module: conv2, weight:  0.9375 bias:  0.9375 , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_function: relu_1, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_function: max_pool2d_1, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_method: view, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_module: fc3, weight:  0.9500 bias:  0.9500 , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_function: relu_2, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_module: fc4, weight:  0.9405 bias:  0.9405 , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_function: relu_3, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for call_module: fc5, , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct sparsity...\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_module: conv1, weight:  0.8333 bias:  0.8333 , output mask:  0.8333 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_function: relu, output mask:  0.8333 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_function: max_pool2d, output mask:  0.8333 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_module: conv2, weight:  0.9375 bias:  0.9375 , output mask:  0.9375 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_function: relu_1, output mask:  0.9375 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_function: max_pool2d_1, output mask:  0.9375 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_method: view, output mask:  0.9375 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_module: fc3, weight:  0.9500 bias:  0.9500 , output mask:  0.9500 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_function: relu_2, output mask:  0.9500 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_module: fc4, weight:  0.9405 bias:  0.9405 , output mask:  0.9405 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_function: relu_3, output mask:  0.9405 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for call_module: fc5, , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect sparsity...\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_module: fc5, , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_function: relu_3, output mask:  0.9405 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_module: fc4, weight:  0.9970 bias:  0.9405 , output mask:  0.9405 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_function: relu_2, output mask:  0.9500 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_module: fc3, weight:  0.9969 bias:  0.9500 , output mask:  0.9500 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_method: view, output mask:  0.9375 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_function: max_pool2d_1, output mask:  0.9375 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_function: relu_1, output mask:  0.9444 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_module: conv2, weight:  0.9896 bias:  0.9375 , output mask:  0.9444 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_function: max_pool2d, output mask:  0.8333 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_function: relu, output mask:  0.8480 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for call_module: conv1, weight:  0.8333 bias:  0.8333 , output mask:  0.8480 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mdim0 sparsity: 0.909091\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mdim1 sparsity: 0.714286\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2023-12-06 20:01:13] \u001b[32mdim0 sparsity: 0.909091\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mdim1 sparsity: 0.714286\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mReplace compressed modules...\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace conv2d with in_channels: 1, out_channels: 1\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace conv2d with in_channels: 1, out_channels: 1\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace linear with new in_features: 25, out_features: 6\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace module (name: fc4, op_type: Linear)\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace linear with new in_features: 6, out_features: 5\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace module (name: fc5, op_type: Linear)\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mreplace linear with new in_features: 5, out_features: 10\u001b[0m\n",
      "[2023-12-06 20:01:13] \u001b[32mSpeedup done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "target_sparsity = .95\n",
    "#config_list = [{\n",
    "    #'op_types': ['Conv2d'],\n",
    "    #'sparse_ratio':target_sparsity\n",
    "#}]\n",
    "#config_list = [{\n",
    "    #'op_names': ['conv1', 'conv2', 'fc3', 'fc4'],\n",
    "    #'sparse_ratio': target_sparsity,\n",
    "    #'global_group_id': 'fourLayers'\n",
    "#}]\n",
    "\"\"\" config_list = [{\n",
    "    'op_names': ['conv1'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['conv2'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['fc3'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['fc4'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}] \"\"\"\n",
    "config_list = [{\n",
    "    'op_names': ['conv1', 'conv2'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['fc3','fc4'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}]\n",
    "\n",
    "\n",
    "dummy_input = torch.rand(6,1,28,28)\n",
    "config_list = auto_set_denpendency_group_ids(model, config_list, dummy_input)\n",
    "optimizer = prepare_optimizer(model)\n",
    "evaluator = TorchEvaluator(train, optimizer, training_step)\n",
    "\n",
    "sub_pruner = TaylorPruner(model,config_list, evaluator, training_steps=100)\n",
    "scheduled_pruner = AGPPruner(sub_pruner, interval_steps=100, total_times=10)\n",
    "\n",
    "_, masks = scheduled_pruner.compress(max_steps=100 * 10, max_epochs=None)\n",
    "scheduled_pruner.unwrap_model()\n",
    "\n",
    "model = ModelSpeedup(model, dummy_input, masks).speedup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model paramater number:  303\n",
      "LeNet_5(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc3): Linear(in_features=25, out_features=6, bias=True)\n",
      "  (fc4): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (fc5): Linear(in_features=5, out_features=10, bias=True)\n",
      ")\n",
      "    def forward(self, x):\n",
      "        x = F.relu(self.conv1(x))\n",
      "        x = F.max_pool2d(x, 2)\n",
      "        x = F.relu(self.conv2(x))\n",
      "        x = F.max_pool2d(x, 2)\n",
      "\n",
      "        x = F.relu(self.fc3(x.view(-1, 16* 5 * 5)))\n",
      "        x = F.relu(self.fc4(x))\n",
      "        x = self.fc5(x)\n",
      "\n",
      "        return x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Pruned model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "print(model)\n",
    "\n",
    "forward_source = inspect.getsource(model.forward)\n",
    "print(forward_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LeNet_5Pruned(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, int(math.ceil(6-(6*target_sparsity))), 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(int(math.ceil(6-(6*target_sparsity))), int(math.ceil(16-(16*target_sparsity))), 5)\n",
    "        self.fc3 = nn.Linear(int(math.ceil(16-(16*target_sparsity))) * 5 * 5, int(math.ceil(120-(120*target_sparsity))))\n",
    "        self.fc4 = nn.Linear(int(math.ceil(120-(120*target_sparsity))), int(math.ceil(84-(84*target_sparsity))))\n",
    "        self.fc5 = nn.Linear(int(math.ceil(84-(84*target_sparsity))), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.fc3(x.view(-1, int(math.ceil(16-(16*target_sparsity))) * 5 * 5)))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet_5Pruned(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc3): Linear(in_features=25, out_features=6, bias=True)\n",
      "  (fc4): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (fc5): Linear(in_features=5, out_features=10, bias=True)\n",
      ")\n",
      "    def forward(self, x):\n",
      "        x = F.relu(self.conv1(x))\n",
      "        x = F.max_pool2d(x, 2)\n",
      "        x = F.relu(self.conv2(x))\n",
      "        x = F.max_pool2d(x, 2)\n",
      "\n",
      "        x = F.relu(self.fc3(x.view(-1, int(math.ceil(16-(16*target_sparsity))) * 5 * 5)))\n",
      "        x = F.relu(self.fc4(x))\n",
      "        x = self.fc5(x)\n",
      "\n",
      "        return x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelPruned = LeNet_5Pruned().to(device)\n",
    "\n",
    "print(modelPruned)\n",
    "\n",
    "forward_source = inspect.getsource(modelPruned.forward)\n",
    "print(forward_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Epoch 0 / Step 600] Final Acc: 87.41%\n",
      "[Training Epoch 1 / Step 1200] Final Acc: 88.83%\n",
      "[Training Epoch 2 / Step 1800] Final Acc: 89.68%\n",
      "[Training Epoch 3 / Step 2400] Final Acc: 89.89%\n",
      "[Training Epoch 4 / Step 3000] Final Acc: 89.19%\n",
      "[Training Epoch 5 / Step 3600] Final Acc: 89.72%\n",
      "[Training Epoch 6 / Step 4200] Final Acc: 90.48%\n",
      "[Training Epoch 7 / Step 4800] Final Acc: 89.94%\n",
      "[Training Epoch 8 / Step 5400] Final Acc: 90.49%\n",
      "[Training Epoch 9 / Step 6000] Final Acc: 89.0%\n"
     ]
    }
   ],
   "source": [
    "optimizer = prepare_optimizer(modelPruned)\n",
    "train(modelPruned, optimizer, training_step, lr_scheduler=None, max_steps=None, max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model after 10 epochs finetuning acc:  89.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Pruned model after 10 epochs finetuning acc: ', evaluate(modelPruned, test_loader), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
