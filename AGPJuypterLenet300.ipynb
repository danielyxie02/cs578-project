{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Grant Parker\n",
    "#Functions/packages/code taken, adapated, and modified from https://github.com/microsoft/nni/blob/36ba04c94e51eaa2a88b9e6e0a4077f3a9f93004/examples/compression/pruning/scheduled_pruning.py\n",
    "#NNI packages\n",
    "import nni\n",
    "from nni.compression import TorchEvaluator\n",
    "from nni.compression.pruning import TaylorPruner, AGPPruner\n",
    "from nni.compression.utils import auto_set_denpendency_group_ids\n",
    "from nni.compression.speedup import ModelSpeedup\n",
    "\n",
    "\n",
    "#pytorch packages \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#tensor packages \n",
    "from tensorboardX import SummaryWriter\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "from models import LeNet_5\n",
    "from datasets import get_mnist_dataloaders\n",
    "\n",
    "import models\n",
    "import datasets\n",
    "#import modelsNNI\n",
    "\n",
    "import time\n",
    "\n",
    "#imports from Models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import inspect\n",
    "\n",
    "#importing Resnet \n",
    "import torchvision.models as modelsRes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#functions\n",
    "def train(model: torch.nn.Module, optimizer: torch.optim.Optimizer, training_step,\n",
    "          lr_scheduler: _LRScheduler, max_steps: int, max_epochs: int):\n",
    "    assert max_epochs is not None or max_steps is not None\n",
    "    #train_loader, test_loader = prepare_dataloader()\n",
    "    #grant addittion ---\n",
    "    batch_size = 100\n",
    "    train_loader, test_loader = datasets.get_mnist_dataloaders(batch_size,batch_size)\n",
    "\n",
    "    #----\n",
    "    max_steps = max_steps if max_steps else max_epochs * len(train_loader)\n",
    "    max_epochs = max_steps // len(train_loader) + (0 if max_steps % len(train_loader) == 0 else 1)\n",
    "    count_steps = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = training_step((data, target), model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count_steps += 1\n",
    "            if count_steps >= max_steps:\n",
    "                acc = evaluate(model, test_loader)\n",
    "                print(f'[Training Epoch {epoch} / Step {count_steps}] Final Acc: {acc}%')\n",
    "                return\n",
    "        acc = evaluate(model, test_loader)\n",
    "        print(f'[Training Epoch {epoch} / Step {count_steps}] Final Acc: {acc}%')\n",
    "\n",
    "def evaluate(model: torch.nn.Module, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return 100 * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def training_step(batch, model: torch.nn.Module):\n",
    "    output = model(batch[0])\n",
    "    loss = F.cross_entropy(output, batch[1])\n",
    "    return loss\n",
    "\n",
    "def prepare_optimizer(model: torch.nn.Module):\n",
    "    optimize_params = [param for param in model.parameters() if param.requires_grad == True]\n",
    "    optimizer = nni.trace(Adam)(optimize_params, lr=0.01)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_300_100(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(-1, 784)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.fc3(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[Training Epoch 0 / Step 600] Final Acc: 95.16%\n",
      "[Training Epoch 1 / Step 1200] Final Acc: 96.57%\n",
      "[Training Epoch 2 / Step 1800] Final Acc: 96.83%\n",
      "[Training Epoch 3 / Step 2400] Final Acc: 96.87%\n",
      "[Training Epoch 4 / Step 3000] Final Acc: 96.46%\n",
      "[Training Epoch 5 / Step 3600] Final Acc: 97.01%\n",
      "[Training Epoch 6 / Step 4200] Final Acc: 96.88%\n",
      "[Training Epoch 7 / Step 4800] Final Acc: 97.16%\n",
      "[Training Epoch 8 / Step 5400] Final Acc: 97.24%\n",
      "[Training Epoch 9 / Step 6000] Final Acc: 97.36%\n",
      "Original model paramater number:  266610\n",
      "Original model after 10 epochs finetuning acc:  97.36 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"start\")\n",
    "    #grants additions \n",
    "\n",
    "    model = LeNet_300_100().to(device)\n",
    "    #model = modelsRes.resnet18().to(device)\n",
    "    #optimizer = optim.NAdam(model.parameters()) -- did not use this \n",
    "    optimizer = prepare_optimizer(model)\n",
    "    batch_size = 100\n",
    "    train(model, optimizer, training_step, lr_scheduler=None, max_steps=None, max_epochs=50)\n",
    "\n",
    "    train_loader, test_loader = datasets.get_mnist_dataloaders(batch_size, batch_size)\n",
    "    print('Original model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "    print('Original model after 10 epochs finetuning acc: ', evaluate(model, test_loader), '%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Epoch 0 / Step 600] Final Acc: 63.17%\n",
      "[Training Epoch 1 / Step 1000] Final Acc: 23.72%\n",
      "[2023-12-06 21:02:04] \u001b[32mStart to speedup the model...\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[33mWARNING: no multi-dimension masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2023-12-06 21:02:04] \u001b[33mWARNING: no multi-dimension masks found.\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mInfer module masks...\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate original variables\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for call_method: view, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for call_module: fc1, weight:  0.9900 bias:  0.9900 , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for call_function: relu, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for call_module: fc2, weight:  0.9900 bias:  0.9900 , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for call_function: relu_1, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct sparsity...\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for call_method: view, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for call_module: fc1, weight:  0.9900 bias:  0.9900 , output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for call_function: relu, output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for call_module: fc2, weight:  0.9900 bias:  0.9900 , output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for call_function: relu_1, output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect sparsity...\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for call_function: relu_1, output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for call_module: fc2, weight:  0.9999 bias:  0.9900 , output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for call_function: relu, output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for call_module: fc1, weight:  0.9900 bias:  0.9900 , output mask:  0.9900 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for call_method: view, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[33mWARNING: no multi-dimension masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2023-12-06 21:02:04] \u001b[33mWARNING: no multi-dimension masks found.\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mReplace compressed modules...\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mreplace linear with new in_features: 784, out_features: 3\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mreplace linear with new in_features: 3, out_features: 1\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mreplace linear with new in_features: 1, out_features: 10\u001b[0m\n",
      "[2023-12-06 21:02:04] \u001b[32mSpeedup done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "target_sparsity = .99\n",
    "config_list = [{\n",
    "    'op_names': ['fc1', 'fc2'],\n",
    "    'sparse_ratio':target_sparsity\n",
    "}]\n",
    "#config_list = [{\n",
    "    #'op_names': ['conv1', 'conv2', 'fc3', 'fc4'],\n",
    "    #'sparse_ratio': target_sparsity,\n",
    "    #'global_group_id': 'fourLayers'\n",
    "#}]\n",
    "\"\"\" config_list = [{\n",
    "    'op_names': ['conv1'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['conv2'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['fc3'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['fc4'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}] \"\"\"\n",
    "\"\"\" config_list = [{\n",
    "    'op_names': ['conv1', 'conv2'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}, {\n",
    "    'op_names': ['fc3','fc4'],\n",
    "    'global_group_id': 'fourLayers',\n",
    "    'sparse_ratio': target_sparsity,\n",
    "}] \"\"\"\n",
    "\n",
    "\n",
    "dummy_input = torch.rand(6,1,28,28)\n",
    "config_list = auto_set_denpendency_group_ids(model, config_list, dummy_input)\n",
    "optimizer = prepare_optimizer(model)\n",
    "evaluator = TorchEvaluator(train, optimizer, training_step)\n",
    "\n",
    "sub_pruner = TaylorPruner(model,config_list, evaluator, training_steps=100)\n",
    "scheduled_pruner = AGPPruner(sub_pruner, interval_steps=100, total_times=10)\n",
    "\n",
    "_, masks = scheduled_pruner.compress(max_steps=100 * 10, max_epochs=None)\n",
    "scheduled_pruner.unwrap_model()\n",
    "\n",
    "model = ModelSpeedup(model, dummy_input, masks).speedup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model paramater number:  2379\n",
      "LeNet_300_100(\n",
      "  (fc1): Linear(in_features=784, out_features=3, bias=True)\n",
      "  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (fc3): Linear(in_features=1, out_features=10, bias=True)\n",
      ")\n",
      "    def forward(self, x):\n",
      "        x = F.relu(self.fc1(x.view(-1, 784)))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        return F.log_softmax(self.fc3(x), dim=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Pruned model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "print(model)\n",
    "\n",
    "forward_source = inspect.getsource(model.forward)\n",
    "print(forward_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LeNet_300_100Pruned(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, int(math.ceil(300-(300*target_sparsity))))\n",
    "        self.fc2 = nn.Linear(int(math.ceil(300-(300*target_sparsity))), int(math.ceil(100-(100*target_sparsity))))\n",
    "        self.fc3 = nn.Linear(int(math.ceil(100-(100*target_sparsity))), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(-1, 784)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet_300_100(\n",
      "  (fc1): Linear(in_features=784, out_features=3, bias=True)\n",
      "  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (fc3): Linear(in_features=1, out_features=10, bias=True)\n",
      ")\n",
      "    def forward(self, x):\n",
      "        x = F.relu(self.fc1(x.view(-1, 784)))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        return F.log_softmax(self.fc3(x), dim=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelPruned = model\n",
    "\n",
    "print(modelPruned)\n",
    "\n",
    "forward_source = inspect.getsource(modelPruned.forward)\n",
    "print(forward_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Epoch 0 / Step 600] Final Acc: 44.58%\n",
      "[Training Epoch 1 / Step 1200] Final Acc: 45.59%\n",
      "[Training Epoch 2 / Step 1800] Final Acc: 46.8%\n",
      "[Training Epoch 3 / Step 2400] Final Acc: 45.51%\n",
      "[Training Epoch 4 / Step 3000] Final Acc: 46.97%\n",
      "[Training Epoch 5 / Step 3600] Final Acc: 47.48%\n",
      "[Training Epoch 6 / Step 4200] Final Acc: 47.02%\n",
      "[Training Epoch 7 / Step 4800] Final Acc: 47.28%\n",
      "[Training Epoch 8 / Step 5400] Final Acc: 48.12%\n",
      "[Training Epoch 9 / Step 6000] Final Acc: 49.71%\n"
     ]
    }
   ],
   "source": [
    "optimizer = prepare_optimizer(modelPruned)\n",
    "train(modelPruned, optimizer, training_step, lr_scheduler=None, max_steps=None, max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model after 10 epochs finetuning acc:  49.71 %\n"
     ]
    }
   ],
   "source": [
    "print('Pruned model after 10 epochs finetuning acc: ', evaluate(modelPruned, test_loader), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
